Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	STAR_GenomeLength
	1

[Fri Dec 13 16:42:34 2019]
rule STAR_GenomeLength:
    input: ../At_genome/TAIR10_chr_all.fas.fai
    output: ../At_genome/TAIR10_chr_all.fas.gz_STAR_index/GenomeLength
    jobid: 0
    wildcards: fasta=TAIR10_chr_all.fas

[Fri Dec 13 16:42:34 2019]
Finished job 0.
1 of 1 steps (100%) done

===========================================================================
Phoenix Job Utilisation Reporting
===========================================================================
Job Name            : STAR_GenomeLength
Job ID              : 20824838
User                : a1673472
Account             : waite
Cluster             : phoenix
Partition           : cpu
Nodes (List)        : 1 (r3n29)
Cores               : 1
GPUs                : 0
State               : COMPLETED
Submit              : 2019-12-13T16:42:32
Start               : 2019-12-13T16:42:33
End                 : 2019-12-13T16:42:34
Walltime reserved   : 00:05:00
Walltime elapsed (%): 00:00:01  ( 0.3% * reserved)
CPU-time elapsed    : 0.00 core-hours
% CPU used (Total)  : 23.60%    (0.00 core-hours)
% User CPU (Compute): 15.50%    (0.00 core-hours)
% System CPU (I/O)  :  8.00%    (0.00 core-hours)
Mem reserved        : 200M/node
% Mem used (Max)    :  0.41%    (836.00K/node) 
Max Disk Write      : 0.00      (r3n29)
Max Disk Read       : 0.00      (r3n29)
===========================================================================
